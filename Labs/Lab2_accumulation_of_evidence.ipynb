{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "Lab2-accumulation-of-evidence.ipynb",
      "provenance": [],
      "collapsed_sections": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "NcGnAXGVqQK8"
      },
      "source": [
        "# Lab 2 - Evidence Accumulation\n",
        "\n",
        "This lab has three main components:\n",
        "\n",
        "- visualizing the drift-diffusion model\n",
        "- introducing an exploratory agent which uses sensory evidence\n",
        "- demonstrate an agent which uses the DDM to process noisy sensory evidence, and explore how the parameters of the DDM influence the performance of the agent "
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "6AYm4pEtH9O6"
      },
      "source": [
        "## Section - Setup"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "H7wZ20Mhm9Dn"
      },
      "source": [
        "### Install ADMCode and explorationlib"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "mIcWU-2GmQLK"
      },
      "source": [
        "# ADMCode uses an old version of numba\n",
        "!pip install numba==0.48\n",
        "!pip install --upgrade git+https://github.com/clappm/AdaptiveDecisionMaking_2018"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "4ZOPw8ouUMI9"
      },
      "source": [
        "!pip install --upgrade git+https://github.com/parenthetical-e/explorationlib\n",
        "!pip install --upgrade git+https://github.com/MattChanTK/gym-maze.git\n",
        "!pip install celluloid # for the gifs"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "-7EGUFBznE-w"
      },
      "source": [
        "### Import Modules"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "hyRNVQHPa5aT"
      },
      "source": [
        "from __future__ import division\n",
        "from ADMCode import visualize as vis\n",
        "from ADMCode import ddm, sdt\n",
        "\n",
        "import numpy as np\n",
        "import pandas as pd\n",
        "\n",
        "from ipywidgets import interactive\n",
        "import matplotlib.pyplot as plt\n",
        "import seaborn as sns\n",
        "import warnings"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "xchYm8E7XD3L"
      },
      "source": [
        "# Import misc\n",
        "import shutil\n",
        "import glob\n",
        "import os\n",
        "import copy\n",
        "import sys\n",
        "\n",
        "# Vis - 1\n",
        "import numpy as np\n",
        "import seaborn as sns\n",
        "import matplotlib.pyplot as plt\n",
        "\n",
        "# Exp\n",
        "from explorationlib.run import experiment\n",
        "from explorationlib.util import select_exp\n",
        "from explorationlib.util import load\n",
        "from explorationlib.util import save\n",
        "\n",
        "# Agents\n",
        "from explorationlib.agent import DiffusionDiscrete\n",
        "from explorationlib.agent import GradientDiffusionGrid\n",
        "from explorationlib.agent import GradientDiffusionDiscrete\n",
        "from explorationlib.agent import AccumulatorGradientGrid\n",
        "from explorationlib.agent import TruncatedLevyDiscrete\n",
        "\n",
        "# Env\n",
        "from explorationlib.local_gym import ScentGrid\n",
        "from explorationlib.local_gym import create_grid_scent\n",
        "from explorationlib.local_gym import uniform_targets\n",
        "from explorationlib.local_gym import constant_values\n",
        "\n",
        "# Vis - 2\n",
        "from explorationlib.plot import plot_position2d\n",
        "from explorationlib.plot import plot_length_hist\n",
        "from explorationlib.plot import plot_length\n",
        "from explorationlib.plot import plot_targets2d\n",
        "from explorationlib.plot import plot_scent_grid\n",
        "\n",
        "# Score\n",
        "from explorationlib.score import total_reward\n",
        "from explorationlib.score import num_death"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "zp9GIk4pnIXN"
      },
      "source": [
        "### Notebook Config"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Udc4lkT1TW7U"
      },
      "source": [
        "# Pretty plots\n",
        "warnings.simplefilter('ignore', np.RankWarning)\n",
        "warnings.filterwarnings(\"ignore\", module=\"matplotlib\")\n",
        "warnings.filterwarnings(\"ignore\")\n",
        "sns.set(style='white', font_scale=1.3)\n",
        "\n",
        "%matplotlib inline\n",
        "%config InlineBackend.figure_format='retina'\n",
        "%config IPCompleter.greedy=True\n",
        "plt.rcParams[\"axes.facecolor\"] = \"white\"\n",
        "plt.rcParams[\"figure.facecolor\"] = \"white\"\n",
        "plt.rcParams[\"font.size\"] = \"16\"\n",
        "\n",
        "# Dev\n",
        "%load_ext autoreload\n",
        "%autoreload 2"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "cy-vC0rLdVV-"
      },
      "source": [
        "## Section - Simulating the Drift-Diffusion Model\n",
        "\n",
        "Here, we will visualize the DDM in action and see how changes in its parameters affect the accuracy and reaction times of the decision process."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Lc25fuhYnTip"
      },
      "source": [
        "### DDM Parameters"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "sOPFsHmAX0E8"
      },
      "source": [
        "a = .10 # boundary height\n",
        "v = .14 # strong drift-rate\n",
        "tr = .25 # nondecision time (in seconds)\n",
        "z = .5 # starting point ([0,1], fraction of a)\n",
        "\n",
        "dt = .001 # time stepsize\n",
        "si = .1 # sigma (noise scalar)\n",
        "dx = si * np.sqrt(dt) # evidence stepsize (up/down)\n",
        "deadline = 1.75 # max decision time (in sec)\n",
        "ntrials = 1000 # number of trials to simulate\n",
        "\n",
        "parameters = np.array([a, tr, v, z, si, dx, dt])"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "V98ITfR9nWWM"
      },
      "source": [
        "### Generating Data"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "iVoozqscaCvB"
      },
      "source": [
        "df, traces = ddm.sim_ddm_trials(parameters, ntrials, deadline)\n",
        "df.head()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "zS41I8-EnZ9n"
      },
      "source": [
        "### Analyze simulated behavior"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "yhbYLnjtaFTB"
      },
      "source": [
        "accuracy = df.choice.mean()\n",
        "corRT = df[df.choice==1].rt.mean()\n",
        "errRT = df[df.choice==0].rt.mean()\n",
        "\n",
        "print(\"RT (cor) = {:.0f} ms\".format(corRT/dt))\n",
        "print(\"RT (err) = {:.0f} ms\".format(errRT/dt))\n",
        "print(\"Accuracy = {:.0f}%\".format(accuracy*100))"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Mjol5zE5ngXf"
      },
      "source": [
        "### Plot evidence traces"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "HVpDIf4caJEJ"
      },
      "source": [
        "ax = vis.plot_ddm_sims(df, parameters, traces=traces, plot_v=True)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "cBD4hD6I4cbf"
      },
      "source": [
        "ax = vis.plot_ddm_sims(df, parameters, traces=traces[:1], plot_v=True)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "rPqyuEsgoAxV"
      },
      "source": [
        "## Section - Using Sensory Data To Explore"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "xd2mxtoYzoZ1"
      },
      "source": [
        "In this section we take on chemotaxic exploration. We'll compare two of our random agents, levy and diffusion, with a gradient searcher who operates akin to a E. Coli (the simple model, anyway). We'll examine exploration for a single target with a variable scent in an open field.\n",
        "\n",
        "_Note:_ this lab, the open field is defined on a discrete (integer) grid. In previous labs we worked with a continuous field. "
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "MR3f3FQaoeiK"
      },
      "source": [
        "The model of scent in our _sniff_ agent (aka _GradientDiffusionDiscrete_) is as simple as can be:\n",
        "\n",
        "- The agent alternates between sensory measurement and movement.\n",
        "  - When the agent senses its environment, it determines the shape of the scent gradient at its current location.\n",
        "  - Based on the gradient, the agent might change its direction of travel.  Then agent then travels a certain distance in a straight line.\n",
        "- When the scent gradient is positive, meaning you are going \"up\" the gradient, the probability of turning is set to _p pos_. \n",
        "- When the gradient is negative, the turning probability is set to _p neg_. (See code below, for an example). \n",
        "- If the agents turns, the direction is uniform random.\n",
        "- The length of travel before the next sensory measurement is sampled from an exponential distribution just like the _DiffusionDiscrete_\n",
        "\n",
        "For now, we are assuming that sensory detection is a noiseless process: the agent automatically knows whether the gradient is negative or positive, with no possibility for uncertainty.  Later we will consider an agent which needs to accumulate evidence to decide whether the gradient is negative or postive. \n",
        "\n",
        "How much faster can smell get you there?"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "PXpmPjMqQmWX"
      },
      "source": [
        "### Example - 100 trials of each agent"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "aOsbq4KKodRk"
      },
      "source": [
        "# Experiment settings\n",
        "num_experiments = 100\n",
        "num_steps = 1000\n",
        "p_neg = 1\n",
        "p_pos = 0.5\n",
        "scent_sigma = 10\n",
        "\n",
        "\n",
        "# Env\n",
        "detection_radius = 1\n",
        "min_length = 1\n",
        "max_length = 10\n",
        "\n",
        "env = ScentGrid(mode=\"discrete\")\n",
        "boundary = (100, 100)\n",
        "target = (5,5)\n",
        "coord, scent = create_grid_scent(boundary, amplitude=1, sigma=scent_sigma)\n",
        "env.add_scent(target, 1, coord, scent)\n",
        "# TODO plot scent\n",
        "\n",
        "# Agents\n",
        "diff = DiffusionDiscrete(min_length=min_length, scale=1)\n",
        "levy2 = TruncatedLevyDiscrete(min_length=min_length, max_length=max_length, exponent=2)\n",
        "sniff = GradientDiffusionDiscrete(num_actions=4, min_length=min_length, scale=2, p_neg=p_neg, p_pos=p_pos)\n",
        "\n",
        "# Cleanup \n",
        "for path in glob.glob(\"data/test4_*.pkl\"):\n",
        "    os.remove(path)\n",
        "\n",
        "# Run Sims\n",
        "levy2_exp = experiment(\n",
        "    f\"data/test4_levy.pkl\",\n",
        "    levy2,\n",
        "    env,\n",
        "    num_steps=num_steps,\n",
        "    num_experiments=num_experiments,\n",
        "    dump=False,\n",
        "    split_state=True,\n",
        ")\n",
        "diff_exp = experiment(\n",
        "    f\"data/test4_diff.pkl\",\n",
        "    diff,\n",
        "    env,\n",
        "    num_steps=num_steps,\n",
        "    num_experiments=num_experiments,\n",
        "    dump=False,\n",
        "    split_state=True,\n",
        ")\n",
        "sniff_exp = experiment(\n",
        "    f\"data/test4_sniff.pkl\",\n",
        "    sniff,\n",
        "    env,\n",
        "    num_steps=num_steps,\n",
        "    num_experiments=num_experiments,\n",
        "    dump=False,\n",
        "    split_state=True,\n",
        ")"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "aBvPfZyJQJVb"
      },
      "source": [
        "### Plot the scent\n",
        "\n",
        "_Note_: the axis is in matrix space not Grid space. Use this to get a sense of how high and wide the scent is."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "GVcssI-TQLzL"
      },
      "source": [
        "plot_scent_grid(env)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "10a-T69aQc5g"
      },
      "source": [
        "### Plot one walk from each agent\n",
        "\n",
        "(in grid space)"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "kJTudXeZQdsJ"
      },
      "source": [
        "plot_boundary = (100, 100)\n",
        "\n",
        "num_experiment = 0\n",
        "ax = plot_position2d(\n",
        "    select_exp(levy2_exp, num_experiment),\n",
        "    boundary=plot_boundary,\n",
        "    label=\"Levy2\",\n",
        "    color=\"purple\",\n",
        "    alpha=0.6,\n",
        "    figsize=(3, 3),\n",
        ")\n",
        "ax = plot_position2d(\n",
        "    select_exp(diff_exp, num_experiment),\n",
        "    boundary=plot_boundary,\n",
        "    label=\"Diffusion\",\n",
        "    color=\"brown\",\n",
        "    alpha=0.6,\n",
        "    ax=ax,\n",
        ")\n",
        "ax = plot_position2d(\n",
        "    select_exp(sniff_exp, num_experiment),\n",
        "    boundary=plot_boundary,\n",
        "    label=\"Sniff\",\n",
        "    color=\"green\",\n",
        "    alpha=0.6,\n",
        "    ax=ax,\n",
        ")\n",
        "ax = plot_targets2d(\n",
        "    env,\n",
        "    boundary=plot_boundary,\n",
        "    color=\"black\",\n",
        "    alpha=1,\n",
        "    label=\"Targets\",\n",
        "    ax=ax,\n",
        ")   "
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "3zInrWG6RgiF"
      },
      "source": [
        "print(f'Levy - {np.sum(select_exp(levy2_exp, num_experiment)[\"exp_reward\"])}')\n",
        "print(f'Diff - {np.sum(select_exp(diff_exp, num_experiment)[\"exp_reward\"])}')\n",
        "print(f'Sniff - {np.sum(select_exp(sniff_exp, num_experiment)[\"exp_reward\"])}')"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "gibASZ7uTnyr"
      },
      "source": [
        "### Plot Summary Statistics and Distributions"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "sHNh7Sb9TrTt"
      },
      "source": [
        "# Results, names, and colors\n",
        "results = [levy2_exp, diff_exp, sniff_exp]\n",
        "names = [\"Levy\", \"Diffusion\", \"Sniff\"]\n",
        "colors = [\"purple\", \"brown\", \"green\"]\n",
        "\n",
        "# Score by total reward\n",
        "scores = []\n",
        "for name, res, color in zip(names, results, colors):\n",
        "    r = total_reward(res)\n",
        "    scores.append(r)  "
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "J9f-HEbzUCD-"
      },
      "source": [
        "# Tabulate\n",
        "m, sd = [], []\n",
        "for (name, s, c) in zip(names, scores, colors):\n",
        "    m.append(np.mean(s))\n",
        "    sd.append(np.std(s))\n",
        "\n",
        "# Plot\n",
        "fig = plt.figure(figsize=(3, 3))\n",
        "plt.bar(names, m, yerr=sd, color=\"black\", alpha=0.6)\n",
        "plt.ylabel(\"Score\")\n",
        "plt.tight_layout()\n",
        "sns.despine()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "9wZHbCgVULTL"
      },
      "source": [
        "for (name, s, c) in zip(names, scores, colors):\n",
        "    plt.hist(s, label=name, color=c, alpha=0.5, bins=np.arange(min(s),max(s)+1,1))\n",
        "    plt.legend()\n",
        "    plt.xlabel(\"Score\")\n",
        "    plt.tight_layout()\n",
        "    sns.despine()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "uKjeNzt_x2CR"
      },
      "source": [
        "# Section: Introducing Cognition\n",
        "\n",
        "In this section we take on noise, aka uncertainty, in exploration. Our venue is still chemotaxis, but now our sensors are noisy. The presence of this uncertainty makes decisions--of the kind common to decision theory--a necessity. \n",
        "\n",
        "The decision to be made is this: is the gradient increasing or decreasing? \n",
        "\n",
        "For this, we'll add a new kind of gradient searcher, which uses a DDM-style accumulator to make decisions about the direction of the gradient. Each time step of the simulation can be spent thinking (accumulating evidence at the current location) _or_ acting (jumping to the next location). We assume an agent can't think and act at the same time.\n",
        "\n",
        "Food for thought: Is it better to spend time rationally accumulating evidence, or is it better to just act?\n",
        "\n",
        "A bit of warning: in previous sections we have used only one metric, either search efficiency or total reward. In this section, to really understand the thinking-action trade-off, we'll be looking at the results from a few more angles. These are:\n",
        "- average reward \n",
        "- best reward\n",
        "- total distance travelled\n",
        "- number of deaths*\n",
        "\n",
        "*Any experimental trial which does not lead to finding at least a single target (aka reward) means the exploring agent dies. It's a harsh noisy world we live in, after all. \n",
        "\n",
        "We'll look at a noisy, somewhat target-filled, domain and explore how speed, accuracy, and death rate are influenced by the parameters of our drift-diffusion model."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ALb83ucKfZ35"
      },
      "source": [
        "### Example: Influence of drift rate on performance\n",
        "\n",
        "Based on what you have been told so far, how would you expect increases in the _drift rate_ to affect average rewards, best rewards, and deaths in an open field task, with sparse targets and noisy scents?\n",
        "\n",
        "Here, drift rate can be conceptualized as the fidelity of sensory signal, like a sort of signal-to-noise ratio."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "bgb_lZy0fS5x"
      },
      "source": [
        "### Create environment\n",
        "\n",
        "The name of the env for this section is once again the _ScentGrid_. \n",
        "\n",
        "Let's add some targets and scents to it."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "d49GnVpAfBJh"
      },
      "source": [
        "# Shared exp parameters\n",
        "num_steps = 200\n",
        "max_steps = 10\n",
        "seed_value = 5838\n",
        "\n",
        "min_length = 1\n",
        "step_size = 0.1\n",
        "\n",
        "noise_sigma = 2\n",
        "detection_radius = 1\n",
        "num_targets = 250 \n",
        "target_boundary = (100, 100)\n",
        "\n",
        "# Env\n",
        "env = ScentGrid(mode=None)\n",
        "env.seed(seed_value)\n",
        "\n",
        "# Targets\n",
        "prng = np.random.RandomState(seed_value)\n",
        "targets = uniform_targets(num_targets, target_boundary, prng=prng)\n",
        "values = constant_values(targets, 1)\n",
        "\n",
        "# Scents\n",
        "coord, scent = create_grid_scent(target_boundary, amplitude=1, sigma=10)\n",
        "scents = [scent for _ in range(len(targets))]\n",
        "env.add_scents(targets, values, coord, scents, noise_sigma=noise_sigma)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "1_T5V_pOfuH2"
      },
      "source": [
        "\n",
        "### Drift rates\n",
        "\n",
        "Using the _env_ defined above explore the following drift rates:"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Zm6JhR05fNzo"
      },
      "source": [
        "# Our parameters \n",
        "drift_rates = [0.25, 0.75, 1.0, 1.25, 1.5]\n",
        "\n",
        "# For plotting\n",
        "colors = [\"darkgreen\", \"seagreen\", \"cadetblue\", \"steelblue\", \"mediumpurple\"]\n",
        "names = drift_rates # list(range(5))"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "_ST92j53gRRP"
      },
      "source": [
        "### Run\n",
        "100 experiments for each drift rate"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "DjNYpQqXgA75"
      },
      "source": [
        "# Exp params\n",
        "threshold = 3.0\n",
        "accumulate_sigma = 1.0\n",
        "\n",
        "num_experiments = 100\n",
        "\n",
        "# Run\n",
        "results = []\n",
        "for i, drift_rate in zip(names, drift_rates):\n",
        "    accum = AccumulatorGradientGrid(\n",
        "        min_length=min_length, \n",
        "        max_steps=max_steps, \n",
        "        drift_rate=drift_rate, \n",
        "        threshold=threshold,\n",
        "        accumulate_sigma=accumulate_sigma\n",
        "    )\n",
        "    accum.seed(seed_value)\n",
        "    # !\n",
        "    exp = experiment(\n",
        "        f\"accum_{i}\",\n",
        "        accum,\n",
        "        env,\n",
        "        num_steps=num_steps,\n",
        "        num_experiments=num_experiments,\n",
        "        dump=False,\n",
        "        split_state=True,\n",
        "        seed=seed_value\n",
        "    )\n",
        "    results.append(exp)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "XUaG8PAEghNe"
      },
      "source": [
        "### Plot an example"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Xp_r9LRtgjBK"
      },
      "source": [
        "plot_boundary = (50, 50)\n",
        "num_experiment = 0\n",
        "ax = None\n",
        "for i, result, color in zip(names, results, colors):\n",
        "    ax = plot_position2d(\n",
        "        select_exp(result, num_experiment),\n",
        "        boundary=plot_boundary,\n",
        "        label=i,\n",
        "        color=color,\n",
        "        alpha=1,\n",
        "        ax=ax,\n",
        "    )\n",
        "ax = plot_targets2d(\n",
        "    env,\n",
        "    boundary=plot_boundary,\n",
        "    color=\"black\",\n",
        "    alpha=1,\n",
        "    label=\"Targets\",\n",
        "    ax=ax,\n",
        ")"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "SVWOOd2nhb-G"
      },
      "source": [
        "### Plot several metrics\n",
        "Distance, death, best reward, average reward\n",
        "\n",
        "Note: the model code follows the _drift rate_, See the def. of \"names\" above."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ubcbKdYeypbc"
      },
      "source": [
        "# Score\n",
        "scores = []\n",
        "for result in results:  \n",
        "    l = 0.0\n",
        "    for r in result:\n",
        "        l += r[\"agent_total_l\"][-1]\n",
        "    scores.append(l)   \n",
        "\n",
        "# Tabulate\n",
        "m, sd = [], []\n",
        "for s in scores:\n",
        "    m.append(np.mean(s))\n",
        "\n",
        "# -\n",
        "fig = plt.figure(figsize=(3, 3))\n",
        "plt.bar([str(n) for n in names], m, color=\"black\", alpha=0.6)\n",
        "plt.ylabel(\"Total distance\")\n",
        "plt.xlabel(\"Model code\")\n",
        "plt.tight_layout()\n",
        "sns.despine()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "8-HO7k8tys_V"
      },
      "source": [
        "# Score\n",
        "scores = []\n",
        "for result in results:\n",
        "    scores.append(num_death(result))   \n",
        "\n",
        "# -\n",
        "fig = plt.figure(figsize=(3, 3))\n",
        "plt.bar([str(n) for n in names], scores, color=\"black\", alpha=0.6)\n",
        "plt.ylabel(\"Deaths\")\n",
        "plt.xlabel(\"Model code\")\n",
        "plt.tight_layout()\n",
        "sns.despine()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Jg5VrFNJyulv"
      },
      "source": [
        "# Score\n",
        "scores = []\n",
        "for result in results:\n",
        "    r = total_reward(result)\n",
        "    scores.append(r)   \n",
        "\n",
        "# Tabulate\n",
        "m = []\n",
        "for s in scores:\n",
        "    m.append(np.max(s))\n",
        "\n",
        "# -\n",
        "fig = plt.figure(figsize=(3, 3))\n",
        "plt.bar([str(n) for n in names], m, color=\"black\", alpha=0.6)\n",
        "plt.ylabel(\"Best score\")\n",
        "plt.xlabel(\"Model code\")\n",
        "plt.tight_layout()\n",
        "sns.despine()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "sOkEfjcZywLl"
      },
      "source": [
        "# Score\n",
        "scores = []\n",
        "for result in results:  \n",
        "    r = total_reward(result)\n",
        "    scores.append(r)   \n",
        "\n",
        "# Tabulate\n",
        "m, sd = [], []\n",
        "for s in scores:\n",
        "    m.append(np.mean(s))\n",
        "    sd.append(np.std(s))\n",
        "\n",
        "# Plot means\n",
        "fig = plt.figure(figsize=(3, 3))\n",
        "plt.bar([str(n) for n in names], m, yerr=sd, color=\"black\", alpha=0.6)\n",
        "plt.ylabel(\"Avg. score\")\n",
        "plt.xlabel(\"Model code\")\n",
        "plt.tight_layout()\n",
        "sns.despine()\n",
        "\n",
        "# Dists of means\n",
        "fig = plt.figure(figsize=(6, 3))\n",
        "for (i, s, c) in zip(names, scores, colors):\n",
        "    plt.hist(s, label=i, color=c, alpha=0.5, bins=list(range(1,50,1)))\n",
        "    plt.legend()\n",
        "    plt.xlabel(\"Score\")\n",
        "    plt.tight_layout()\n",
        "    sns.despine()"
      ],
      "execution_count": null,
      "outputs": []
    }
  ]
}