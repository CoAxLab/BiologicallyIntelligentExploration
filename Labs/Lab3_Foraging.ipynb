{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "Lab3_Foraging.ipynb",
      "provenance": [],
      "collapsed_sections": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "0mRaxS0rSKVO"
      },
      "source": [
        "# LAB 3 - Demonstration of a Tolman-Eichenbaum Machine"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Sw4kde8j-8f4"
      },
      "source": [
        "## Setup"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "XD-nuASP2MJH"
      },
      "source": [
        "### Upload model files\n",
        "\n",
        "- click files tab on left\n",
        "- click 'upload to session storage'\n",
        "- upload params_10000.pt and tem_10000.pt"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "rywOe2YH2BUv"
      },
      "source": [
        "### Get the source code from the Torch TEM repo"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "nGnIsIweL4A-"
      },
      "source": [
        "# original repo https://github.com/jbakermans/torch_tem.git\n",
        "!git clone https://github.com/clappm/torch_tem.git temp\n",
        "!cp -R temp/. .\n",
        "!rm -rf temp"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Gj9RS-Bz2jcd"
      },
      "source": [
        "### Import libraries and source files"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ZOJ6qxO6L5j3"
      },
      "source": [
        "\"\"\"\n",
        "Created on Thu Jul  2 09:35:57 2020\n",
        "\n",
        "@author: jacobb\n",
        "\"\"\"\n",
        "\n",
        "# Standard library imports\n",
        "import numpy as np\n",
        "import torch\n",
        "import glob\n",
        "import matplotlib.pyplot as plt\n",
        "import importlib.util\n",
        "# Own module imports. Note how model module is not imported, since we'll used the model from the training run\n",
        "import world\n",
        "import analyse\n",
        "import plot\n",
        "\n",
        "import json"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "6LCa3E2JNWhi"
      },
      "source": [
        "### Notebook config"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "mVznPw0SNUlY"
      },
      "source": [
        "%config IPCompleter.greedy=True\n",
        "%load_ext autoreload\n",
        "%autoreload 2"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Z2ACnjIh3Frf"
      },
      "source": [
        "### Set random seeds for reproducibility"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "4KJPdUz23HQF"
      },
      "source": [
        "np.random.seed(0)\n",
        "torch.manual_seed(0)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "HazJafoG_Hjo"
      },
      "source": [
        "## Load model"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "IbuLIfrf3Wu6"
      },
      "source": [
        "### Choose which trained model to load\n",
        "\n",
        "- \"index\" is the number in the params_XXXX.pt and tem_XXXX.pt files."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "xQ0Q8Xi33PJm"
      },
      "source": [
        "index = '10000'"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "D8683JOI3sFB"
      },
      "source": [
        "### Load the model spec\n",
        "\n",
        "- use import library to import module from specified path"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "bDOMNmea3vaA"
      },
      "source": [
        "model_spec = importlib.util.spec_from_file_location(\"model\", 'model.py')\n",
        "model = importlib.util.module_from_spec(model_spec)\n",
        "model_spec.loader.exec_module(model)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "XJ80M8IO3vrS"
      },
      "source": [
        "### Load the parameters of the model"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "SnWbFhMi3v4m"
      },
      "source": [
        "params = torch.load('params_' + index + '.pt')"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "xWEXK5Ct37tI"
      },
      "source": [
        "### Create a new tem model with the loaded parameters"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "fxCM6R3U367S"
      },
      "source": [
        "tem = model.Model(params)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "XlBRQlxH4Ctz"
      },
      "source": [
        "### Load the model weights after training"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "8aUyNPgQ37E3"
      },
      "source": [
        "model_weights = torch.load('tem_' + index + '.pt')"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "7IGxKsgE4ICD"
      },
      "source": [
        "### Set the model weights to the loaded trained model weights"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ZwXb6fl74HT3"
      },
      "source": [
        "tem.load_state_dict(model_weights)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "M1KP-2LX4OJW"
      },
      "source": [
        "### Make sure model is in evaluate mode"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "JHhEpKVW37IY"
      },
      "source": [
        "tem.eval()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "iSydUbaf_eE9"
      },
      "source": [
        "## Set up environments"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "yLjvgPNj8JUX"
      },
      "source": [
        "### Make list of all the environment files"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "QHhYuZSm8Gdb"
      },
      "source": [
        "envs = list(glob.iglob('envs/*'))\n",
        "\n",
        "envs"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "mHvvDrb5Upys"
      },
      "source": [
        "### Load one of the JSONs for inspection"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Z-jrRg2RSr2d"
      },
      "source": [
        "env_to_read = envs[0]\n",
        "f = open(env_to_read,)\n",
        "env_data = json.load(f)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "4_jDEVWdUwr2"
      },
      "source": [
        "### print contents"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "tb0VGFsWUndN"
      },
      "source": [
        "for key,val in env_data.items():\n",
        "  print(key)\n",
        "  if isinstance(val,list):\n",
        "    [print(x) for x in val]\n",
        "  else:\n",
        "    print(val)\n",
        "  print()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "8Zq79GOCU0Pq"
      },
      "source": [
        "### print contents of a single location"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "CtiD-AR9UUuY"
      },
      "source": [
        "for key,val in env_data['locations'][0].items():\n",
        "  print(key)\n",
        "  if isinstance(val,list):\n",
        "    [print(x) for x in val]\n",
        "  else:\n",
        "    print(val)\n",
        "  print()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "vuFUXJGS8YmY"
      },
      "source": [
        "### Set which environments will include shiny objects (none)"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "19UcXJOf8a5q"
      },
      "source": [
        "shiny_envs = [False, False, False]"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ixvuiQjU8rBe"
      },
      "source": [
        "### Set the number of walks to execute in parallel (batch size)"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "oxlL2EMB8nle"
      },
      "source": [
        "n_walks = len(shiny_envs)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "t1sqrFTe8ulT"
      },
      "source": [
        "### Create environments from the environments list"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "BbBT1vAA9JVF"
      },
      "source": [
        "environments = [world.World(graph, randomise_observations=True, shiny=(params['shiny'] if shiny_envs[env_i] else None)) \n",
        "                for env_i, graph in enumerate(envs)]\n",
        "\n",
        "environments"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "wGFtCxFI_prR"
      },
      "source": [
        "## Generating walks"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "oziVuO6I9YHJ"
      },
      "source": [
        "### Determine the length of each walk"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "jlZ3_DxQ9bDi"
      },
      "source": [
        "walk_len = np.median([env.n_locations * 50 for env in environments]).astype(int)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "jj7O0y4_9dcY"
      },
      "source": [
        "### Generate walks for each environment"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Alpd4JW-9sSp"
      },
      "source": [
        "walks = [env.generate_walks(walk_len, 1)[0] for env in environments]"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "EeBfPuNP98cU"
      },
      "source": [
        "### Generate model input from specified walk and environment\n",
        "\n",
        "- group steps from all environments together to feed to model in parallel"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "epGiSpk6-Auc"
      },
      "source": [
        "model_input = [[[[walks[i][j][k]][0] for i in range(len(walks))] for k in range(3)] for j in range(walk_len)]\n",
        "for i_step, step in enumerate(model_input):\n",
        "    model_input[i_step][1] = torch.stack(step[1], dim=0)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "UzOJouS4GSlj"
      },
      "source": [
        "## Run model"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "XBYsLhIq-E_7"
      },
      "source": [
        "### Run a forward pass through the model using this data, without accumulating gradients"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "29nAILb9-Gvg"
      },
      "source": [
        "with torch.no_grad():\n",
        "    forward = tem(model_input, prev_iter=None)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "AQpYX1h9Gdnp"
      },
      "source": [
        "## Analysis"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "bLt156Ab-I6S"
      },
      "source": [
        "### Decide whether to include stay-still actions as valid occasions for inference"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "i__7mrIP-N8-"
      },
      "source": [
        "include_stay_still = True"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Un_oQp3e-KvC"
      },
      "source": [
        "### Compare trained model performance to a node agent and an edge agent"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "eOsS5No0-U1B"
      },
      "source": [
        "correct_model, correct_node, correct_edge = analyse.compare_to_agents(forward, tem, environments, include_stay_still=include_stay_still)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "F97HQYAo-YEV"
      },
      "source": [
        "### Analyse occurrences of zero-shot inference\n",
        "\n",
        "- predict the right observation arriving from a visited node with a new action"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "dgRtIgd6-dvY"
      },
      "source": [
        "zero_shot = analyse.zero_shot(forward, tem, environments, include_stay_still=include_stay_still)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "0JgPQDvb-mf3"
      },
      "source": [
        "### Generate occupancy maps\n",
        "\n",
        "- how much time TEM spends at every location"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Q2Uu2KYv-qNg"
      },
      "source": [
        "occupation = analyse.location_occupation(forward, tem, environments)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "xWEHj1jK-tQM"
      },
      "source": [
        "### Generate rate maps"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "puxKucLz-wFV"
      },
      "source": [
        "g, p = analyse.rate_map(forward, tem, environments)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "asOT_NpW-yDa"
      },
      "source": [
        "### Calculate accuracy leaving from and arriving to each location"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "nPyyKy4F-2uu"
      },
      "source": [
        "from_acc, to_acc = analyse.location_accuracy(forward, tem, environments)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "6_rouxnO-5Nl"
      },
      "source": [
        "# Plotting"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "PE7ahemvGj_i"
      },
      "source": [
        "### Choose which environment to plot"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "AnIZSxxqGmUn"
      },
      "source": [
        "env_to_plot = 1\n",
        "\n",
        "envs[env_to_plot]"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "K2_dRkBJGoC0"
      },
      "source": [
        "### When averaging environments, e.g. for calculating average accuracy, decide which environments to include"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "VZe_ObGNG2H_"
      },
      "source": [
        "envs_to_avg = shiny_envs if shiny_envs[env_to_plot] else [not shiny_env for shiny_env in shiny_envs]"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "stZLAzYMG9Sl"
      },
      "source": [
        "### Plot results of agent comparison and zero-shot inference analysis"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "jz77pncWG_AQ"
      },
      "source": [
        "filt_size = 41\n",
        "plt.figure()\n",
        "plt.plot(analyse.smooth(np.mean(np.array([env for env_i, env in enumerate(correct_model) if envs_to_avg[env_i]]),0)[1:], filt_size), label='tem')\n",
        "plt.plot(analyse.smooth(np.mean(np.array([env for env_i, env in enumerate(correct_node) if envs_to_avg[env_i]]),0)[1:], filt_size), label='node')\n",
        "plt.plot(analyse.smooth(np.mean(np.array([env for env_i, env in enumerate(correct_edge) if envs_to_avg[env_i]]),0)[1:], filt_size), label='edge')\n",
        "plt.ylim(0, 1)\n",
        "plt.legend()\n",
        "plt.title('Zero-shot inference: ' + str(np.mean([np.mean(env) for env_i, env in enumerate(zero_shot) if envs_to_avg[env_i]]) * 100) + '%')\n",
        "plt.show()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "zkammOvKHPnD"
      },
      "source": [
        "### Plot rate maps for all cells"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "eeU0dADCHTUO"
      },
      "source": [
        "plot.plot_cells(p[env_to_plot], g[env_to_plot], environments[env_to_plot], n_f_ovc=(params['n_f_ovc'] if 'n_f_ovc' in params else 0), columns = 25)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "GEF-OBhOHa6A"
      },
      "source": [
        "### Plot accuracy separated by location"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "_jFkjCx2Hf51"
      },
      "source": [
        "plt.figure()\n",
        "ax = plt.subplot(1,2,1)\n",
        "plot.plot_map(environments[env_to_plot], np.array(to_acc[env_to_plot]), ax)\n",
        "ax.set_title('Accuracy to location')\n",
        "ax = plt.subplot(1,2,2)\n",
        "plot.plot_map(environments[env_to_plot], np.array(from_acc[env_to_plot]), ax)\n",
        "ax.set_title('Accuracy from location');"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "--VBv5B0HlUn"
      },
      "source": [
        "### Plot occupation per location, then add walks on top"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "dMZ_qWcpWH0B"
      },
      "source": [
        "ax = plot.plot_map(environments[env_to_plot], np.array(occupation[env_to_plot])/sum(occupation[env_to_plot])*environments[env_to_plot].n_locations, \n",
        "                   min_val=0, max_val=2, ax=None, shape='square', radius=1/np.sqrt(environments[env_to_plot].n_locations))\n",
        "ax = plot.plot_walk(environments[env_to_plot], walks[env_to_plot], ax=ax, n_steps=max(1, int(len(walks[env_to_plot])/500)))\n",
        "plt.title('Walk and average occupation');"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "NgafclSiXdD9"
      },
      "source": [
        ""
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "wbyxuOemI5qd"
      },
      "source": [
        "# Extra: TEM training (Don't run)"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "R-m9LGqMI7iW"
      },
      "source": [
        "!git clone https://github.com/jbakermans/torch_tem.git temp\n",
        "!cp -R temp/. .\n",
        "!rm -rf temp"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "yJwGLiCfI9q3"
      },
      "source": [
        "\"\"\"\n",
        "Created on Thu Feb 20 14:57:45 2020\n",
        "\n",
        "@author: jacobb\n",
        "\"\"\"\n",
        "\n",
        "# Standard library imports\n",
        "import numpy as np\n",
        "import torch\n",
        "from torch.utils.tensorboard import SummaryWriter\n",
        "import time\n",
        "import glob, os, shutil\n",
        "import importlib.util\n",
        "# Own module imports\n",
        "import world\n",
        "import utils\n",
        "import parameters\n",
        "import model as model\n",
        "\n",
        "\n",
        "from tqdm import tqdm   "
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "yuU0yyLRJD1K"
      },
      "source": [
        "# Set random seeds for reproducibility\n",
        "np.random.seed(0)\n",
        "torch.manual_seed(0)\n",
        "\n",
        "# Either load a trained model and continue training, or start afresh\n",
        "load_existing_model = False;\n",
        "if load_existing_model:\n",
        "    # Choose which trained model to load\n",
        "    date = '2020-10-06' # 2020-07-05 run 0 for successful node agent\n",
        "    run = '2'\n",
        "    i_start = 40\n",
        "    \n",
        "    # Set all paths from existing run \n",
        "    run_path, train_path, model_path, save_path, script_path, envs_path = utils.set_directories(date, run)\n",
        "    \n",
        "    # Load the model: use import library to import module from specified path\n",
        "    model_spec = importlib.util.spec_from_file_location(\"model\", script_path + '/model.py')\n",
        "    model = importlib.util.module_from_spec(model_spec)\n",
        "    model_spec.loader.exec_module(model)\n",
        "    \n",
        "    # Load the parameters of the model\n",
        "    params = torch.load(model_path + '/params_' + str(i_start) + '.pt')\n",
        "    # But certain parameters (like total nr of training iterations) may need to be copied from the current set of parameters\n",
        "    new_params = {'train_it':40000}\n",
        "    # Update those in params\n",
        "    for key in new_params:\n",
        "        params[key] = new_params[key]\n",
        "    \n",
        "    # Create a new tem model with the loaded parameters\n",
        "    tem = model.Model(params)\n",
        "    #tem.to(device)\n",
        "    # Load the model weights after training\n",
        "    model_weights = torch.load(model_path + '/tem_' + str(i_start) + '.pt')\n",
        "    # Set the model weights to the loaded trained model weights\n",
        "    tem.load_state_dict(model_weights)\n",
        "    \n",
        "    # Make list of all the environments that this model was trained on\n",
        "    envs = list(glob.iglob(envs_path + '/*'))\n",
        "    \n",
        "    # And increase starting iteration by 1, since the loaded model already carried out the current starting iteration\n",
        "    i_start = i_start + 1\n",
        "else:\n",
        "    # Start training from step 0\n",
        "    i_start = 0\n",
        "    \n",
        "    # Create directories for storing all information about the current run\n",
        "    run_path, train_path, model_path, save_path, script_path, envs_path = utils.make_directories()\n",
        "    # Save all python files in current directory to script directory\n",
        "    files = glob.iglob(os.path.join('.', '*.py'))\n",
        "    for file in files:\n",
        "        if os.path.isfile(file):\n",
        "            shutil.copy2(file, os.path.join(script_path, file))        \n",
        "            \n",
        "    # Initalise hyperparameters for model\n",
        "    params = parameters.parameters()\n",
        "    # Save parameters\n",
        "    np.save(os.path.join(save_path, 'params'), params)       \n",
        "    \n",
        "    # And create instance of TEM with those parameters\n",
        "    tem = model.Model(params)\n",
        "    #tem.to(device)\n",
        "    \n",
        "    # Create list of environments that we will sample from during training to provide TEM with trajectory input\n",
        "    envs = ['./envs/5x5.json']\n",
        "    # Save all environment files that are being used in training in the script directory\n",
        "    for file in set(envs):\n",
        "        shutil.copy2(file, os.path.join(envs_path, os.path.basename(file)))    \n",
        "\n",
        "# Create a tensor board to stay updated on training progress. Start tensorboard with tensorboard --logdir=runs\n",
        "writer = SummaryWriter(train_path)\n",
        "# Create a logger to write log output to file\n",
        "logger = utils.make_logger(run_path)\n",
        "\n",
        "# Make an ADAM optimizer for TEM\n",
        "adam = torch.optim.Adam(tem.parameters(), lr = params['lr_max'])\n",
        "\n",
        "# Make set of environments: one for each batch, randomly choosing to use shiny objects or not\n",
        "environments = [world.World(graph, randomise_observations=True, shiny=(params['shiny'] if np.random.rand() < params['shiny_rate'] else None)) for graph in np.random.choice(envs,params['batch_size'])]\n",
        "# Initialise whether a state has been visited for each world\n",
        "visited = [[False for _ in range(env.n_locations)] for env in environments]\n",
        "# And make a single walk for each environment, where walk lengths can be any between the min and max length to de-sychronise world switches\n",
        "walks = [env.generate_walks(params['n_rollout']*np.random.randint(params['walk_it_min'], params['walk_it_max']), 1)[0] for env in environments]\n",
        "# Initialise the previous iteration as None: we start from the beginning of the walk, so there is no previous iteration yet\n",
        "prev_iter = None\n",
        "\n",
        "# Train TEM on walks in different environment\n",
        "for i in tqdm(range(i_start, params['train_it'])):\n",
        "    \n",
        "    # Get start time for function timing\n",
        "    start_time = time.time()\n",
        "    # Get updated parameters for this backprop iteration\n",
        "    eta_new, lambda_new, p2g_scale_offset, lr, walk_length_center, loss_weights = parameters.parameter_iteration(i, params)\n",
        "    # Update eta and lambda\n",
        "    tem.hyper['eta'] = eta_new\n",
        "    tem.hyper['lambda'] = lambda_new\n",
        "    # Update scaling of offset for variance of inferred grounded position\n",
        "    tem.hyper['p2g_scale_offset'] = p2g_scale_offset\n",
        "    # Update learning rate (the neater torch-way of doing this would be a scheduler, but this is quick and easy)\n",
        "    for param_group in adam.param_groups:\n",
        "        param_group['lr'] = lr            \n",
        "    \n",
        "    # Make an empty chunk that will be fed to TEM in this backprop iteration\n",
        "    chunk = []\n",
        "    # For each environment: fill chunk by popping the first batch_size steps of the walk\n",
        "    for env_i, walk in enumerate(walks):\n",
        "        # Make sure this walk has enough steps in it for a whole backprop iteration\n",
        "        if len(walk) < params['n_rollout']:\n",
        "            # If it doesn't: create a new environment \n",
        "            environments[env_i] = world.World(envs[np.random.randint(len(envs))], randomise_observations=True, shiny=(params['shiny'] if np.random.rand() < params['shiny_rate'] else None))\n",
        "            # Initialise whether a state has been visited for each world\n",
        "            visited[env_i] = [False for _ in range(environments[env_i].n_locations)]            \n",
        "            # Generate a new walk on that environment\n",
        "            walk = environments[env_i].generate_walks(params['n_rollout']*np.random.randint(walk_length_center - params['walk_it_window'] * 0.5, walk_length_center + params['walk_it_window'] * 0.5), 1)[0]\n",
        "            # And store it in walks array\n",
        "            walks[env_i] = walk\n",
        "            # Finally, set the action of the previous iteration for this environment to zero, to indicate that this is a new walk\n",
        "            prev_iter[0].a[env_i] = None\n",
        "            # Log progress\n",
        "            logger.info('Iteration {:d}: new walk of length {:d} for batch entry {:d}'.format(i, len(walk), env_i))                \n",
        "        # Now pop the first n_rollout steps from this walk and append them to the chunk\n",
        "        for step in range(params['n_rollout']):\n",
        "            # For the first environment: simply copy the components (g, x, a) of each step\n",
        "            if len(chunk) < params['n_rollout']:\n",
        "                chunk.append([[comp] for comp in walk.pop(0)])\n",
        "            # For all next environments: add the components to the existing list of components for each step\n",
        "            else:\n",
        "                for comp_i, comp in enumerate(walk.pop(0)):\n",
        "                    chunk[step][comp_i].append(comp)\n",
        "    # Stack all observations (x, component 1) into tensors along the first dimension for batch processing\n",
        "    for i_step, step in enumerate(chunk):\n",
        "        chunk[i_step][1] = torch.stack(step[1], dim=0)  \n",
        "        \n",
        "    # Forward-pass this walk through the network\n",
        "    forward = tem(chunk, prev_iter)    \n",
        "    \n",
        "    # Accumulate loss from forward pass\n",
        "    loss = torch.tensor(0.0)\n",
        "    # Make vector for plotting losses\n",
        "    plot_loss = 0\n",
        "    # Collect all losses \n",
        "    for step in forward:            \n",
        "        # Make list of losses included in this step\n",
        "        step_loss = []        \n",
        "        # Only include loss for locations that have been visited before\n",
        "        for env_i, env_visited in enumerate(visited):\n",
        "            if env_visited[step.g[env_i]['id']]:\n",
        "                step_loss.append(loss_weights*torch.stack([l[env_i] for l in step.L]))\n",
        "            else:\n",
        "                env_visited[step.g[env_i]['id']] = True\n",
        "        # Stack losses in this step along first dimension, then average across that dimension to get mean loss for this step\n",
        "        step_loss = torch.tensor(0)  if not step_loss else torch.mean(torch.stack(step_loss, dim=0), dim=0) \n",
        "        # Save all separate components of loss for monitoring\n",
        "        plot_loss = plot_loss + step_loss.detach().numpy()\n",
        "        # And sum all components, then add them to total loss of this step\n",
        "        loss = loss + torch.sum(step_loss)\n",
        "\n",
        "    # Reset gradients\n",
        "    adam.zero_grad()\n",
        "    # Do backward pass to calculate gradients with respect to total loss of this chunk\n",
        "    loss.backward(retain_graph=True)\n",
        "    # Then do optimiser step to update parameters of model\n",
        "    adam.step()\n",
        "    # Update the previous iteration for the next chunk with the final step of this chunk, removing all operation history\n",
        "    prev_iter = [forward[-1].detach()]\n",
        "    \n",
        "    # Compute model accuracies\n",
        "    acc_p, acc_g, acc_gt = np.mean([[np.mean(a) for a in step.correct()] for step in forward], axis=0)\n",
        "    acc_p, acc_g, acc_gt = [a * 100 for a in (acc_p, acc_g, acc_gt)]        \n",
        "    # Log progress \n",
        "    if i % 10 == 0:\n",
        "        # Write series of messages to logger from this backprop iteration\n",
        "        logger.info('Finished backprop iter {:d} in {:.2f} seconds.'.format(i,time.time()-start_time))\n",
        "        logger.info('Loss: {:.2f}. <p_g> {:.2f} <p_x> {:.2f} <x_gen> {:.2f} <x_g> {:.2f} <x_p> {:.2f} <g> {:.2f} <reg_g> {:.2f} <reg_p> {:.2f}'.format(loss.detach().numpy(), *plot_loss))\n",
        "        logger.info('Accuracy: <p> {:.2f}% <g> {:.2f}% <gt> {:.2f}%'.format(acc_p, acc_g, acc_gt))\n",
        "        logger.info('Parameters: <max_hebb> {:.2f} <eta> {:.2f} <lambda> {:.2f} <p2g_scale_offset> {:.2f}'.format(np.max(np.abs(prev_iter[0].M[0].numpy())), tem.hyper['eta'], tem.hyper['lambda'], tem.hyper['p2g_scale_offset']))\n",
        "        logger.info('Weights:' + str([w for w in loss_weights.numpy()]))\n",
        "        logger.info(' ')\n",
        "        # Also write progress to tensorboard, and all loss components. Order: [L_p_g, L_p_x, L_x_gen, L_x_g, L_x_p, L_g, L_reg_g, L_reg_p]\n",
        "        writer.add_scalar('Losses/Total', loss.detach().numpy(), i)\n",
        "        writer.add_scalar('Losses/p_g', plot_loss[0], i)\n",
        "        writer.add_scalar('Losses/p_x', plot_loss[1], i)\n",
        "        writer.add_scalar('Losses/x_gen', plot_loss[2], i)\n",
        "        writer.add_scalar('Losses/x_g', plot_loss[3], i)\n",
        "        writer.add_scalar('Losses/x_p', plot_loss[4], i)\n",
        "        writer.add_scalar('Losses/g', plot_loss[5], i)\n",
        "        writer.add_scalar('Losses/reg_g', plot_loss[6], i)\n",
        "        writer.add_scalar('Losses/reg_p', plot_loss[7], i)\n",
        "        writer.add_scalar('Accuracies/p', acc_p, i)\n",
        "        writer.add_scalar('Accuracies/g', acc_g, i)\n",
        "        writer.add_scalar('Accuracies/gt', acc_gt, i)\n",
        "    # Also store the internal state (all learnable parameters) and the hyperparameters periodically \n",
        "    if i % 1000 == 0:\n",
        "        torch.save(tem.state_dict(), model_path + '/tem_' + str(i) + '.pt')\n",
        "        torch.save(tem.hyper, model_path + '/params_' + str(i) + '.pt')\n",
        "\n",
        "# Save the final state of the model after training has finished\n",
        "torch.save(tem.state_dict(), model_path + '/tem_' + str(i) + '.pt')\n",
        "torch.save(tem.hyper, model_path + '/params_' + str(i) + '.pt')"
      ],
      "execution_count": null,
      "outputs": []
    }
  ]
}