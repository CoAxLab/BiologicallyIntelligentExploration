{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/CoAxLab/BiologicallyIntelligentExploration/blob/main/Labs/Lab7_Foraging.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "mhT-lilScl3G"
      },
      "source": [
        "# Lab 7 - Biologically intelligent foraging\n",
        "\n",
        "This lab has 4 main components designed to give provide an theoretical and experiental/interactive understanding of foraging in patchy environments.\n",
        "\n",
        "Sections:\n",
        "1. Consider foraging in \"patchy\" environments, and build a simulated patchy environment.\n",
        "1. Predict and evaluate the behavior of agents with different exploration strategies in the patcy environment.\n",
        "1. Predict and evaluate how agents' behavior & performance will change as characteristics of the patchy environment change.\n"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Background"
      ],
      "metadata": {
        "id": "hKkGUWhIhFds"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Real environments are \"patchy\".\n",
        "- So far, we've been playing around with simulated environments where food (\"targets\") are spread uniformly over space.\n",
        "- In reality, environments are often \"patchy\". For example, berries or flowers may be concentrated on isolated bushes, which are spaced apart from one another (see the natural environment below).\n",
        "![natural patchy environment](https://cdn.pixabay.com/photo/2021/07/04/16/41/yakima-valley-6386896_1280.jpg)\n",
        "\n",
        "### Patchy environments define the foraging problem.\n",
        "- The problem of foraging requires that an organism navigate through an environment to find food, balancing the metabolic costs of movement with the energy provided by collected morsels.\n",
        "- In an environment where targets are dispersed uniformly, foraging is rather simple - moving around from via some form of random walk, collecting targets, perhaps with behavior imformed by scent cues.\n",
        "- A patchy environment complicates things - with no food in between patches, between-patch movement can become dangerous at long transit times. Patchy environments thus demand a foraging strategy that is sensitive to the sparsely-dense stucture of food availability.\n",
        "\n",
        "### We can think of optimal foraging in terms of a simplified model.\n",
        "- Charnov (1976) proposed a model of optimal foraging.\n",
        "- Charnov's model formulates foraging space as divided into sections (patches) of different types, and the inter-patch space between them. See the illustration of this from his paper below (and consider how this simple model matches the real environment above so much better than uniformly distributed targets!).\n",
        "![Charnov patch model illustration screenshot](https://raw.githubusercontent.com/CoAxLab/BiologicallyIntelligentExploration/main/Labs/Charnov_patches_screenshot.png)\n",
        "- When we think about foraging in this way, it becomes clear that there is an important distinction between time spent *in* and *between* patches.\n",
        "- Critically, off-patch time and on-patch time (for different patch types) determines energy intake rate for organisms.\n",
        "- In Charnov's model, within-patch energy is depleted as a forager consumes the energy within that patch. Thus there is a point at which an optimal forager should leave a patch in aims of finding another. This is where the formulas in his marginal value come into play.\n",
        "\n",
        "Next up, let's get set up to run some patch environment simulations!"
      ],
      "metadata": {
        "id": "fYdbAhg2tyIU"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Section - Setup\n",
        "\n",
        "We need to load the usual explorationlib library and supporting functions. For this lab specifically, we will be loading a certain *branch* of exploration library - one where I have coded functions for the creation and evaluation of behavior in patchy environments."
      ],
      "metadata": {
        "id": "cKiFhdTxk_n3"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "Change the directory to where we want to clone in the specific explorationlib code library branch."
      ],
      "metadata": {
        "id": "6D8lV0W3qxmH"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "KHs0UqG6XlKX"
      },
      "outputs": [],
      "source": [
        "cd /content"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Clone in the `target-patch-dev` explorationlib branch (the branch that has our new patchy environment functions)."
      ],
      "metadata": {
        "id": "l1xLyj8Aq5bN"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "Ng6J6MWeX8NY"
      },
      "outputs": [],
      "source": [
        "!git clone -b target-patch-dev https://github.com/coaxlab/explorationlib"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Change the working directory to the cloned library, so that we can load modules from it later on."
      ],
      "metadata": {
        "id": "kuEFcNxXrIQa"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "-UhLuFYpXqOE"
      },
      "outputs": [],
      "source": [
        "cd /content/explorationlib"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Install some other supporting code libraries, like gym-maze, which some explorationlib simulated environment code relies on."
      ],
      "metadata": {
        "id": "y15pYjBArTuw"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "KNjgieoaW_xL"
      },
      "outputs": [],
      "source": [
        "!pip install --upgrade git+https://github.com/MattChanTK/gym-maze.git\n",
        "!pip install celluloid # for the gifs"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Import specific modules from the libraries we loaded. We'll use these modules to create and plot enviornments, run experiments with different exploration agents in these environments, visualize their behaviors, and evaluate their performance according to various metrics."
      ],
      "metadata": {
        "id": "ymQNT9dlrvnL"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "7TTuWHQEcF1O"
      },
      "outputs": [],
      "source": [
        "# Import misc\n",
        "import shutil\n",
        "import glob\n",
        "import os\n",
        "import copy\n",
        "import sys\n",
        "\n",
        "# Vis - 1\n",
        "import numpy as np\n",
        "import seaborn as sns\n",
        "import matplotlib.pyplot as plt\n",
        "\n",
        "# Exp\n",
        "from explorationlib.run import experiment\n",
        "from explorationlib.util import select_exp\n",
        "from explorationlib.util import load\n",
        "from explorationlib.util import save\n",
        "\n",
        "# Agents\n",
        "from explorationlib.agent import DiffusionGrid\n",
        "from explorationlib.agent import DiffusionDiscrete\n",
        "from explorationlib.agent import GradientDiffusionGrid\n",
        "from explorationlib.agent import GradientDiffusionDiscrete\n",
        "from explorationlib.agent import AccumulatorGradientGrid\n",
        "from explorationlib.agent import AccumulatorInfoGrid\n",
        "from explorationlib.agent import TruncatedLevyDiscrete\n",
        "\n",
        "# Env\n",
        "from explorationlib.local_gym import ScentGrid\n",
        "from explorationlib.local_gym import create_grid_scent\n",
        "from explorationlib.local_gym import create_grid_scent_patches\n",
        "from explorationlib.local_gym import uniform_targets\n",
        "from explorationlib.local_gym import uniform_patch_targets\n",
        "from explorationlib.local_gym import constant_values\n",
        "\n",
        "# Vis - 2\n",
        "from explorationlib.plot import plot_position2d\n",
        "from explorationlib.plot import plot_length_hist\n",
        "from explorationlib.plot import plot_length\n",
        "from explorationlib.plot import plot_targets2d\n",
        "from explorationlib.plot import plot_scent_grid\n",
        "\n",
        "# Score\n",
        "from explorationlib.score import total_reward\n",
        "from explorationlib.score import num_death\n",
        "from explorationlib.score import on_off_patch_time"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Section 1 - Building a simulated patchy environment\n",
        "\n",
        "- Below is some environment setup code that should look pretty standard compared to the previous labs you've seen in this class.\n",
        "- The key difference is the generation of targets using a new function, `uniform_patch_targets()` - in other labs we've only used `uniform_targets()`.\n",
        "- This new function randomly places circular patches in the environment, and then places targets at random with uniform probability within each patch.\n",
        "- To specify the characteristics of the patchy environment we want to generate, we supply information about how many patches we want (`n_patches`), how many targets we want per patch (`n_per_patch`), and how large we want each patch to be (`radius`).\n",
        "- To be clear, our simulation won't be perfect - this function can create overlapping patches, and our simulations don't take into account the depletion of patches over time.\n",
        "\n",
        "Fill in the code below and run to create a patch environmet with *7 patches* of *10 targets each*. Make each patch have a *radius of 2 units*."
      ],
      "metadata": {
        "id": "pu48IqFjlfeN"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "PmMf7zZ2YVd5"
      },
      "outputs": [],
      "source": [
        "# Noise and missing scents\n",
        "p_scent = 0.5\n",
        "noise_sigma = 1\n",
        "\n",
        "# Shared agent parameters\n",
        "num_experiments = 50\n",
        "num_steps = 400\n",
        "seed_value = 6074\n",
        "\n",
        "# Environment parameters\n",
        "detection_radius = 1\n",
        "max_steps = 1\n",
        "min_length = 1\n",
        "n_patches = 7 # FILL IN         # number of patches\n",
        "n_per_patch = 10 # FILL IN      # number targets per patch\n",
        "radius = 2 # FILL IN            # radius of each patch\n",
        "target_boundary = (10, 10)\n",
        "\n",
        "# Generate patches of argets\n",
        "prng = np.random.RandomState(seed_value)\n",
        "targets, patch_locs = uniform_patch_targets(n_patches, target_boundary, radius, n_per_patch, prng=prng)\n",
        "\n",
        "values = constant_values(targets, 1)\n",
        "\n",
        "# Generate scents from targets\n",
        "scents = []\n",
        "for _ in range(len(targets)):\n",
        "    coord, scent = create_grid_scent_patches(\n",
        "        target_boundary, p=1.0, amplitude=1, sigma=2)\n",
        "    scents.append(scent)\n",
        "\n",
        "# Create ScentGrid environment\n",
        "env = ScentGrid(mode=None)\n",
        "env.seed(seed_value)\n",
        "env.add_scents(targets, values, coord, scents, noise_sigma=noise_sigma)"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Visualizing this environment\n",
        "\n",
        "Run the code below to visualize the patchy environment that you just built!"
      ],
      "metadata": {
        "id": "3TUxsKoQbtm_"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "377nSrZKYXlA"
      },
      "outputs": [],
      "source": [
        "plot_boundary = (10, 10)\n",
        "num_experiment = 0\n",
        "ax = None\n",
        "ax = plot_targets2d(\n",
        "    env,\n",
        "    boundary=plot_boundary,\n",
        "    color=\"black\",\n",
        "    alpha=1,\n",
        "    label=\"Targets\",\n",
        "    ax=ax,\n",
        ")"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Section 2 - Different exploration strategies in the patchy environment\n",
        "\n",
        "Now we will predict and evaluate the behavior of agents with different exploration strategies in the patcy environment. These are agents that we have used in pervious labs. See those labs to remember how these agents work. \n",
        "\n",
        "Here we will generate 3 different types of agents - one that moves randomly (diffusion on the grid), one that follows chemical signals emitted by targets (chemotaxis), and one that follows information gain (infotaxis)."
      ],
      "metadata": {
        "id": "EJtso6kplths"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "51ELNt49mN9U"
      },
      "outputs": [],
      "source": [
        "# Agents\n",
        "\n",
        "# Random search agent\n",
        "diff = DiffusionGrid(min_length=min_length, scale=1)\n",
        "diff.seed(seed_value)\n",
        "\n",
        "drift_rate = 1\n",
        "threshold = 3\n",
        "\n",
        "# Chemotaxis agent\n",
        "chemo = AccumulatorGradientGrid(\n",
        "    min_length=min_length, \n",
        "    max_steps=max_steps, \n",
        "    drift_rate=drift_rate, \n",
        "    threshold=threshold,\n",
        "    accumulate_sigma=1\n",
        ")\n",
        "chemo.seed(seed_value)\n",
        "\n",
        "\n",
        "# Infotaxis agent\n",
        "info = AccumulatorInfoGrid(\n",
        "    min_length=min_length, \n",
        "    max_steps=max_steps, \n",
        "    drift_rate=drift_rate, \n",
        "    threshold=threshold,\n",
        "    accumulate_sigma=1\n",
        ")\n",
        "\n",
        "info.seed(seed_value)\n",
        "\n"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "**Note:** you may like to start the next experiments running as you answer these questions."
      ],
      "metadata": {
        "id": "fPYY1S7njHHs"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Question 2.1\n",
        "\n",
        "Which agent do you think will spend the most time in patches? Which agent do you think will spend the least time in patches? Why?"
      ],
      "metadata": {
        "id": "pFvD0qrih8Io"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Write your answer here as a comment. Explain yourself."
      ],
      "metadata": {
        "id": "Qn76WmvPiOj_"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Question 2.2\n",
        "\n",
        "Which agent do you think will accumulate the most reward (spend the most time next to targets?). Which do you think will spend the least? Why?"
      ],
      "metadata": {
        "id": "duITA8hciZBL"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Write your answer here as a comment. Explain yourself."
      ],
      "metadata": {
        "id": "N4o3G235it2n"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Question 2.3\n",
        "\n",
        "Which agent do you think will have the most deaths? Which do you think will have the least? Why?"
      ],
      "metadata": {
        "id": "DzfHsCj3iw-_"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Write your answer here as a comment. Explain yourself."
      ],
      "metadata": {
        "id": "HJhoshaSiu-A"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Run the code below to perform a number of experiments, simulating how these different agents behave in the patch environment that you built."
      ],
      "metadata": {
        "id": "a9zl0zcujDIV"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "yx2xNi1LmWSy"
      },
      "outputs": [],
      "source": [
        "# Experiments\n",
        "rand_exp = experiment(\n",
        "    f\"rand\",\n",
        "    diff,\n",
        "    env,\n",
        "    num_steps=num_steps,\n",
        "    num_experiments=num_experiments,\n",
        "    dump=False,\n",
        "    split_state=True,\n",
        "    seed=seed_value\n",
        ")\n",
        "chemo_exp = experiment(\n",
        "    f\"chemo\",\n",
        "    chemo,\n",
        "    env,\n",
        "    num_steps=num_steps,\n",
        "    num_experiments=num_experiments,\n",
        "    dump=False,\n",
        "    split_state=True,\n",
        "    seed=seed_value\n",
        ")\n",
        "info_exp = experiment(\n",
        "    f\"info\",\n",
        "    info,\n",
        "    env,\n",
        "    num_steps=num_steps,\n",
        "    num_experiments=num_experiments,\n",
        "    dump=False,\n",
        "    split_state=True,\n",
        "    seed=seed_value\n",
        ")"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Run the code below to plot behavior of each agent type during one experiment example."
      ],
      "metadata": {
        "id": "zv0lEbzjjwRp"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "csb8q_6kmd_N"
      },
      "outputs": [],
      "source": [
        "plot_boundary = (10, 10)\n",
        "\n",
        "# -\n",
        "num_experiment = 5\n",
        "ax = None\n",
        "ax = plot_position2d(\n",
        "    select_exp(chemo_exp, num_experiment),\n",
        "    boundary=plot_boundary,\n",
        "    label=\"Chemo\",\n",
        "    color=\"blue\",\n",
        "    alpha=0.6,\n",
        "    ax=ax,\n",
        ")\n",
        "ax = plot_position2d(\n",
        "    select_exp(info_exp, num_experiment),\n",
        "    boundary=plot_boundary,\n",
        "    label=\"Info\",\n",
        "    color=\"green\",\n",
        "    alpha=0.6,\n",
        "    ax=ax,\n",
        ")\n",
        "ax = plot_position2d(\n",
        "    select_exp(rand_exp, num_experiment),\n",
        "    boundary=plot_boundary,\n",
        "    label=\"Rando\",\n",
        "    color=\"grey\",\n",
        "    alpha=0.8,\n",
        "    ax=ax,\n",
        ")\n",
        "ax = plot_targets2d(\n",
        "    env,\n",
        "    boundary=plot_boundary,\n",
        "    color=\"black\",\n",
        "    alpha=1,\n",
        "    label=\"Targets\",\n",
        "    ax=ax,\n",
        ")"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Question 2.4\n",
        "\n",
        "Describe the behavior of each agent type in the experiment visualization above. Does the behavior match what you expected? Why do you think you see the specific pattern of behavior for each agent?"
      ],
      "metadata": {
        "id": "kHwF9brYj6xt"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Write your answer here as a comment. Explain yourself."
      ],
      "metadata": {
        "id": "duPbtZ-vkaF_"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Quantify time on-patches for each agent type\n",
        "\n",
        "The code below makes use of a new scoring function, `on_off_patch_time()`. This function takes experiment results data and analyzes it to see how many time steps were spent on vs. off patches. Run the code block below to measure and plot the proportion of total time steps each agent spends on patches. See if the results match your predictions."
      ],
      "metadata": {
        "id": "8S1yLZ6ck0n2"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "j6R7wg_OmjwW"
      },
      "outputs": [],
      "source": [
        "# Results\n",
        "results = [rand_exp, info_exp, chemo_exp]\n",
        "names = [\"Rando\", \"Info\", \"Chemo\"]\n",
        "colors = [\"blue\", \"green\", \"grey\"]\n",
        "\n",
        "# Score by on_patch_time #eff\n",
        "scores = []\n",
        "for name, res, color in zip(names, results, colors):\n",
        "    #scores.append(num_death(res))\n",
        "    on_patch_steps, off_patch_steps = on_off_patch_time(res, num_experiments, patch_locs, radius)\n",
        "    scores.append(np.divide(on_patch_steps,(np.array(on_patch_steps) + off_patch_steps)))   \n",
        "\n",
        "# Tabulate\n",
        "m, sd = [], []\n",
        "for (name, s, c) in zip(names, scores, colors):\n",
        "    m.append(np.mean(s))\n",
        "    sd.append(np.std(s))\n",
        "\n",
        "# Plot means\n",
        "fig = plt.figure(figsize=(5, 4))\n",
        "plt.bar(names, m, yerr=sd, color=\"black\", alpha=0.6)\n",
        "plt.ylabel(\"Proportion of time steps on patches\")\n",
        "plt.tight_layout()\n",
        "sns.despine()\n",
        "\n",
        "# Dists\n",
        "fig = plt.figure(figsize=(5, 4))\n",
        "for (name, s, c) in zip(names, scores, colors):\n",
        "    plt.hist(s, label=name, color=c, alpha=0.5, bins=np.linspace(0, np.max(scores), 50))\n",
        "    plt.legend()\n",
        "    plt.xlabel(\"proportion of time steps on patches\")\n",
        "    plt.tight_layout()\n",
        "    sns.despine()"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Quantify total reward for each agent type\n",
        "\n",
        "Check if your predictions were correct."
      ],
      "metadata": {
        "id": "kehI4hL2n2nx"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "eca2mXrQmmxJ"
      },
      "outputs": [],
      "source": [
        "# Results\n",
        "results = [rand_exp, info_exp, chemo_exp]\n",
        "names = [\"Rando\", \"Info\", \"Chemo\"]\n",
        "colors = [\"blue\", \"green\", \"grey\"]\n",
        "\n",
        "# Score by eff\n",
        "scores = []\n",
        "for name, res, color in zip(names, results, colors):\n",
        "    r = total_reward(res)\n",
        "    scores.append(r)   \n",
        "\n",
        "# Tabulate\n",
        "m, sd = [], []\n",
        "for (name, s, c) in zip(names, scores, colors):\n",
        "    m.append(np.mean(s))\n",
        "    sd.append(np.std(s))\n",
        "\n",
        "# Plot means\n",
        "fig = plt.figure(figsize=(5, 4))\n",
        "plt.bar(names, m, yerr=sd, color=\"black\", alpha=0.6)\n",
        "plt.ylabel(\"Total reward\")\n",
        "plt.tight_layout()\n",
        "sns.despine()\n",
        "\n",
        "# Dists\n",
        "fig = plt.figure(figsize=(5, 4))\n",
        "for (name, s, c) in zip(names, scores, colors):\n",
        "    plt.hist(s, label=name, color=c, alpha=0.5, bins=np.linspace(0, np.max(scores), 50))\n",
        "    plt.legend()\n",
        "    plt.xlabel(\"Score\")\n",
        "    plt.tight_layout()\n",
        "    sns.despine()"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Quantify deaths for each agent type\n",
        "\n",
        "Check if your predictions were correct."
      ],
      "metadata": {
        "id": "RcPykectoC4e"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Results\n",
        "results = [rand_exp, info_exp, chemo_exp]\n",
        "names = [\"Rando\", \"Info\", \"Chemo\"]\n",
        "colors = [\"blue\", \"green\", \"grey\"]\n",
        "\n",
        "# Score by eff\n",
        "scores = []\n",
        "for name, res, color in zip(names, results, colors):\n",
        "    scores.append(num_death(res))   \n",
        "\n",
        "# Tabulate\n",
        "m, sd = [], []\n",
        "for (name, s, c) in zip(names, scores, colors):\n",
        "    m.append(np.mean(s))\n",
        "    sd.append(np.std(s))\n",
        "\n",
        "# Plot means\n",
        "fig = plt.figure(figsize=(4, 3))\n",
        "plt.bar(names, m, yerr=sd, color=\"black\", alpha=0.6)\n",
        "plt.ylabel(\"Deaths\")\n",
        "plt.tight_layout()\n",
        "sns.despine()"
      ],
      "metadata": {
        "id": "fa9g7sxUoIDw"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Question 2.5\n",
        "\n",
        "Were any of your predictions wrong? If so, what do you think caused the unexpected results?"
      ],
      "metadata": {
        "id": "vwMrfxy5oetS"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Write your answer here as a comment. Explain yourself."
      ],
      "metadata": {
        "id": "Lwo22a3-or08"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Question 2.6\n",
        "\n",
        "Compare time on patch, total rewards, and deaths for the Chemo agent. What does this pattern tell you about the influence of a simple chemotaxis strategy for foraging?"
      ],
      "metadata": {
        "id": "hIv_A-CZ06EI"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Write your answer here as a comment. Explain yourself."
      ],
      "metadata": {
        "id": "nWkoxqDF1aTh"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Section 3 - Exploration strategies in different patchy environments"
      ],
      "metadata": {
        "id": "yZAHaaZKlw69"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Question 3.1\n",
        "\n",
        "Next, try creating a new patch environment just like our first one, but with only two patches of 20 targets each. Make predictions as to how the performance of each agent type will change and why. Make predictions for on-patch-proportion, total reward, and death."
      ],
      "metadata": {
        "id": "T85Pr9Ep2NWo"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Add your predictions here, as a python comment in this cell below."
      ],
      "metadata": {
        "id": "LuzZrBh72tD1"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Noise and missing scents\n",
        "p_scent = 0.5\n",
        "noise_sigma = 1\n",
        "\n",
        "# Shared agent parameters\n",
        "num_experiments = 50\n",
        "num_steps = 400\n",
        "seed_value = 5074               # seed value for random number generator\n",
        "\n",
        "# Environment parameters\n",
        "detection_radius = 1\n",
        "max_steps = 1\n",
        "min_length = 1\n",
        "n_patches = 2 # FILL IN         # number of patches\n",
        "n_per_patch = 20 # FILL IN      # number targets per patch\n",
        "radius = 2 # FILL IN            # radius of each patch\n",
        "target_boundary = (10, 10)\n",
        "\n",
        "# Generate patches of argets\n",
        "prng = np.random.RandomState(seed_value)\n",
        "targets, patch_locs = uniform_patch_targets(n_patches, target_boundary, radius, n_per_patch, prng=prng)\n",
        "\n",
        "values = constant_values(targets, 1)\n",
        "\n",
        "# Generate scents from targets\n",
        "scents = []\n",
        "for _ in range(len(targets)):\n",
        "    coord, scent = create_grid_scent_patches(\n",
        "        target_boundary, p=1.0, amplitude=1, sigma=2)\n",
        "    scents.append(scent)\n",
        "\n",
        "# Create ScentGrid environment\n",
        "env = ScentGrid(mode=None)\n",
        "env.seed(seed_value)\n",
        "env.add_scents(targets, values, coord, scents, noise_sigma=noise_sigma)"
      ],
      "metadata": {
        "id": "K8Jt--YeqLMw"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "plot_boundary = (10, 10)\n",
        "num_experiment = 0\n",
        "ax = None\n",
        "ax = plot_targets2d(\n",
        "    env,\n",
        "    boundary=plot_boundary,\n",
        "    color=\"black\",\n",
        "    alpha=1,\n",
        "    label=\"Targets\",\n",
        "    ax=ax,\n",
        ")"
      ],
      "metadata": {
        "id": "Z9yg-5ifvxLF"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Experiments\n",
        "rand_exp = experiment(\n",
        "    f\"rand\",\n",
        "    diff,\n",
        "    env,\n",
        "    num_steps=num_steps,\n",
        "    num_experiments=num_experiments,\n",
        "    dump=False,\n",
        "    split_state=True,\n",
        "    seed=seed_value\n",
        ")\n",
        "chemo_exp = experiment(\n",
        "    f\"chemo\",\n",
        "    chemo,\n",
        "    env,\n",
        "    num_steps=num_steps,\n",
        "    num_experiments=num_experiments,\n",
        "    dump=False,\n",
        "    split_state=True,\n",
        "    seed=seed_value\n",
        ")\n",
        "info_exp = experiment(\n",
        "    f\"info\",\n",
        "    info,\n",
        "    env,\n",
        "    num_steps=num_steps,\n",
        "    num_experiments=num_experiments,\n",
        "    dump=False,\n",
        "    split_state=True,\n",
        "    seed=seed_value\n",
        ")"
      ],
      "metadata": {
        "id": "B1fvlqrvqWyk"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Results\n",
        "results = [rand_exp, info_exp, chemo_exp]\n",
        "names = [\"Rando\", \"Info\", \"Chemo\"]\n",
        "colors = [\"blue\", \"green\", \"grey\"]\n",
        "\n",
        "# Score by on_patch_time #eff\n",
        "scores = []\n",
        "for name, res, color in zip(names, results, colors):\n",
        "    #scores.append(num_death(res))\n",
        "    on_patch_steps, off_patch_steps = on_off_patch_time(res, num_experiments, patch_locs, radius)\n",
        "    scores.append(np.divide(on_patch_steps,(np.array(on_patch_steps) + off_patch_steps)))   \n",
        "\n",
        "# Tabulate\n",
        "m, sd = [], []\n",
        "for (name, s, c) in zip(names, scores, colors):\n",
        "    m.append(np.mean(s))\n",
        "    sd.append(np.std(s))\n",
        "\n",
        "# Plot means\n",
        "fig = plt.figure(figsize=(5, 4))\n",
        "plt.bar(names, m, yerr=sd, color=\"black\", alpha=0.6)\n",
        "plt.ylabel(\"Proportion of time steps on patches\")\n",
        "plt.tight_layout()\n",
        "sns.despine()\n",
        "\n",
        "# Dists\n",
        "fig = plt.figure(figsize=(5, 4))\n",
        "for (name, s, c) in zip(names, scores, colors):\n",
        "    plt.hist(s, label=name, color=c, alpha=0.5, bins=np.linspace(0, np.max(scores), 50))\n",
        "    plt.legend()\n",
        "    plt.xlabel(\"proportion of time steps on patches\")\n",
        "    plt.tight_layout()\n",
        "    sns.despine()"
      ],
      "metadata": {
        "id": "hSaXAH1Wt9EN"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Results\n",
        "results = [rand_exp, info_exp, chemo_exp]\n",
        "names = [\"Rando\", \"Info\", \"Chemo\"]\n",
        "colors = [\"blue\", \"green\", \"grey\"]\n",
        "\n",
        "# Score by eff\n",
        "scores = []\n",
        "for name, res, color in zip(names, results, colors):\n",
        "    r = total_reward(res)\n",
        "    scores.append(r)   \n",
        "\n",
        "# Tabulate\n",
        "m, sd = [], []\n",
        "for (name, s, c) in zip(names, scores, colors):\n",
        "    m.append(np.mean(s))\n",
        "    sd.append(np.std(s))\n",
        "\n",
        "# Plot means\n",
        "fig = plt.figure(figsize=(5, 4))\n",
        "plt.bar(names, m, yerr=sd, color=\"black\", alpha=0.6)\n",
        "plt.ylabel(\"Total reward\")\n",
        "plt.tight_layout()\n",
        "sns.despine()\n",
        "\n",
        "# Dists\n",
        "fig = plt.figure(figsize=(5, 4))\n",
        "for (name, s, c) in zip(names, scores, colors):\n",
        "    plt.hist(s, label=name, color=c, alpha=0.5, bins=np.linspace(0, np.max(scores), 50))\n",
        "    plt.legend()\n",
        "    plt.xlabel(\"Score\")\n",
        "    plt.tight_layout()\n",
        "    sns.despine()"
      ],
      "metadata": {
        "id": "2qwCNGWW1kPm"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Results\n",
        "results = [rand_exp, info_exp, chemo_exp]\n",
        "names = [\"Rando\", \"Info\", \"Chemo\"]\n",
        "colors = [\"blue\", \"green\", \"grey\"]\n",
        "\n",
        "# Score by eff\n",
        "scores = []\n",
        "for name, res, color in zip(names, results, colors):\n",
        "    scores.append(num_death(res))   \n",
        "\n",
        "# Tabulate\n",
        "m, sd = [], []\n",
        "for (name, s, c) in zip(names, scores, colors):\n",
        "    m.append(np.mean(s))\n",
        "    sd.append(np.std(s))\n",
        "\n",
        "# Plot means\n",
        "fig = plt.figure(figsize=(4, 3))\n",
        "plt.bar(names, m, yerr=sd, color=\"black\", alpha=0.6)\n",
        "plt.ylabel(\"Deaths\")\n",
        "plt.tight_layout()\n",
        "sns.despine()"
      ],
      "metadata": {
        "id": "d1bnWRkFqfMh"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Question 3.2\n",
        "\n",
        "Did the results match your predictions? If not, why do you think you saw the results that came up?"
      ],
      "metadata": {
        "id": "NDJuNeNV2z40"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Write your answer here as a comment. Explain yourself."
      ],
      "metadata": {
        "id": "I7UUz21u3Xhh"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Question 3.3\n",
        "\n",
        "Re-run the above simulations in Section 3, but change the seed value for the random number generator. Do this four different times, once each with the following values: 2074, 3074, 4074, 5074. \n",
        "\n",
        "What do you see in the performance of the agents with each new seed value (which specifies different unique environments)? What does this tell you about the the difference between the Info and Chemo agents in particular?"
      ],
      "metadata": {
        "id": "UyU_sOjhzdzV"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Write your answer here as a comment. Explain yourself."
      ],
      "metadata": {
        "id": "ykSd7RVC1cYG"
      },
      "execution_count": null,
      "outputs": []
    }
  ],
  "metadata": {
    "colab": {
      "collapsed_sections": [],
      "provenance": [],
      "include_colab_link": true
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}